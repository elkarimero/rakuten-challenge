{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09cd0f7b-2f22-4289-ad55-1d776f250721",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-18 21:38:05.357570: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1742330285.386585   12310 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1742330285.397115   12310 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1742330285.432453   12310 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1742330285.432490   12310 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1742330285.432493   12310 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1742330285.432494   12310 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-03-18 21:38:05.445841: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.19.0\n",
      "Num GPUs Available:  1\n",
      "Found 77316 files belonging to 27 classes.\n",
      "Using 61853 files for training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1742330345.803314   12310 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5563 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 77316 files belonging to 27 classes.\n",
      "Using 15463 files for validation.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Imports nécessaires pour construire un modèle LeNet \n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Rescaling\n",
    "\n",
    "# Pour importer le datasets\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Pour la compilation du modèle\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "# Pour visualiser les performances\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# dataviz\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "%matplotlib inline\n",
    "\n",
    "print(tf.__version__)\n",
    "tf.config.experimental.set_memory_growth(tf.config.list_physical_devices('GPU')[0], True)\n",
    "tf.keras.backend.clear_session()\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\n",
    "# Chargement du dataset\n",
    "#dir_name = \"/mnt/c/Users/karim/rakuten/images/data_clean/images_deep/sample\"\n",
    "dir_name = \"/mnt/c/Users/karim/rakuten/images/data_clean/images_deep/train\"\n",
    "img_size = (224, 224)  # Taille cible\n",
    "batch_size = 128\n",
    "class_names = sorted(os.listdir(dir_name))\n",
    "nb_class = len(class_names)\n",
    "\n",
    "train_ds = image_dataset_from_directory(\n",
    "    dir_name,\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    subset=\"training\",\n",
    "    validation_split=0.2,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "val_ds = image_dataset_from_directory(\n",
    "    dir_name,\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    subset=\"validation\",\n",
    "    validation_split=0.2,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "\n",
    "# Ajout d'optimisation : mise en cache et préchargement\n",
    "#train_ds = train_ds.cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "#val_ds = val_ds.cache().prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ab9f4a-5132-444a-b23f-dde239cbb64b",
   "metadata": {},
   "source": [
    "## Analyse de l'entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69963274-edda-436b-8c5b-918476e8e1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_results(model_history, model_name):\n",
    "    # Récupérer les données d'entraînement et de validation\n",
    "    train_loss = model_history.history[\"loss\"]\n",
    "    val_loss = model_history.history[\"val_loss\"]\n",
    "    train_accuracy =  model_history.history[\"accuracy\"]\n",
    "    val_accuracy = model_history.history[\"val_accuracy\"]\n",
    "    \n",
    "    plt.figure(figsize=(20, 8))\n",
    "    \n",
    "    # Tracer la perte\n",
    "    plt.subplot(121)\n",
    "    plt.plot(train_loss)\n",
    "    plt.plot(val_loss)\n",
    "    plt.title(model_name + \": Perte d'entraînement et de validation\")\n",
    "    plt.ylabel('Perte ')\n",
    "    plt.xlabel('Époque')\n",
    "    plt.legend(['Entraînement', 'Validation'], loc='best')\n",
    "    \n",
    "    # Tracer l'erreur absolue moyenne (MAE)\n",
    "    plt.subplot(122)\n",
    "    plt.plot(train_accuracy)\n",
    "    plt.plot(val_accuracy)\n",
    "    plt.title(model_name+': Accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Époque')\n",
    "    plt.legend(['Entraînement', 'Validation'], loc='best')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226f79b4-50e1-4a43-a62c-f804d32f8d84",
   "metadata": {},
   "source": [
    "## modèle ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd09ad5-9b82-45d4-81bf-05432aaf84cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase 1: Entraînement avec modèle de base gelé\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1742330429.557115   13674 cuda_dnn.cc:529] Loaded cuDNN version 90800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m348/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m44s\u001b[0m 328ms/step - accuracy: 0.0359 - loss: nan "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "\n",
    "# Data augmentation\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomFlip(\"horizontal\"),\n",
    "    tf.keras.layers.RandomRotation(0.2),\n",
    "    tf.keras.layers.RandomZoom(0.2),\n",
    "    tf.keras.layers.RandomContrast(0.2),\n",
    "])\n",
    "\n",
    "\n",
    "# 1. Instancie le modèle pré-entrainé\n",
    "base_model = tf.keras.applications.ResNet50(\n",
    "    input_shape=(224, 224, 3),\n",
    "    include_top=False,\n",
    "    weights='imagenet'\n",
    ")\n",
    "base_model.trainable = False  # Geler le modèle de base\n",
    "\n",
    "\n",
    "# 2. Construire le modèle complet\n",
    "model = tf.keras.Sequential([\n",
    "    # Augmentation de données\n",
    "    data_augmentation,\n",
    "    \n",
    "    # Prétraitement spécifique au modèle\n",
    "    tf.keras.layers.Rescaling(1./127.5, offset=-1),  \n",
    "    \n",
    "    # Modèle de base\n",
    "    base_model,\n",
    "    \n",
    "    # Couches de classification\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "    tf.keras.layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(128, activation='relu',kernel_regularizer=tf.keras.regularizers.l2(0.002)),\n",
    "    tf.keras.layers.Dropout(0.4),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.2,\n",
    "    patience=3,\n",
    "    min_lr=1e-6\n",
    ")\n",
    "\n",
    "# Étape 2: Entraîner avec le modèle de base gelé\n",
    "print(\"Phase 1: Entraînement avec modèle de base gelé\")\n",
    "\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',  \n",
    "    optimizer= tf.keras.optimizers.Adam(learning_rate=1e-3),                 \n",
    "    metrics=['accuracy'])             \n",
    "\n",
    "model_history = model.fit(train_ds,           \n",
    "                           validation_data=val_ds,\n",
    "                           epochs=10,\n",
    "                           callbacks=[early_stopping, reduce_lr])    \n",
    "\n",
    "# Étape 3: Fine-tuning - dégeler partiellement le modèle de base\n",
    "print(\"Phase 2: Fine-tuning\")\n",
    "e\n",
    "base_model.trainable = False\n",
    "\n",
    "for layer in base_model.layers[-20:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Recompiler avec un taux d'apprentissage plus faible\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=2e-5),  \n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Learning rate scheduler\n",
    "import math\n",
    "\n",
    "def lr_scheduler(epoch, lr):\n",
    "    if epoch < 3:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * math.exp(-0.1)  \n",
    "\n",
    "lr_callback = tf.keras.callbacks.LearningRateScheduler(lr_scheduler)\n",
    "\n",
    "# Entraîner avec fine-tuning\n",
    "history_phase2 = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=20,\n",
    "    callbacks=[early_stopping, lr_callback]\n",
    ")\n",
    "\n",
    "\n",
    "# Analyse de l'entainement\n",
    "print(\"Analyse entraintement ResNet50 (base)\")\n",
    "val_loss, val_accuracy = model.evaluate(val_ds)\n",
    "print(f\"Précision de validation finale: {val_accuracy:.4f}\")\n",
    "display_results(model_history, \"ResNet50 (base)\")\n",
    "\n",
    "# Analyse de l'entainement\n",
    "print(\"Analyse entraintement ResNet50 (fine tunning)\")\n",
    "val_loss, val_accuracy = model.evaluate(val_ds)\n",
    "print(f\"Précision de validation finale: {val_accuracy:.4f}\")\n",
    "display_results(history_phase2, \"ResNet50 (fine tunning)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
