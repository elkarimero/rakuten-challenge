{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09cd0f7b-2f22-4289-ad55-1d776f250721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.19.0\n",
      "Num GPUs Available:  1\n",
      "['10', '40', '50']\n",
      "Found 6851 files belonging to 3 classes.\n",
      "Using 5481 files for training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1742071057.468891    1260 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1896 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6851 files belonging to 3 classes.\n",
      "Using 1370 files for validation.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "# Imports nécessaires pour construire un modèle LeNet \n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Rescaling, BatchNormalization\n",
    "\n",
    "# Pour importer le datasets\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "\n",
    "# Pour la compilation du modèle\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "# Pour visualiser les performances\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "%matplotlib inline\n",
    "\n",
    "print(tf.__version__)\n",
    "tf.config.experimental.set_memory_growth(tf.config.list_physical_devices('GPU')[0], True)\n",
    "tf.keras.backend.clear_session()\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\n",
    "# Chargement du dataset\n",
    "dir_name = \"/mnt/c/Users/karim/rakuten/images/data_clean/images_deep/sample\"\n",
    "#dir_name = \"/mnt/c/Users/karim/rakuten/images/data_clean/images_deep/train\"\n",
    "img_size = (224, 224)  # Taille cible\n",
    "batch_size = 128\n",
    "class_names = sorted(os.listdir(dir_name))\n",
    "nb_class = len(class_names)\n",
    "\n",
    "print(class_names)\n",
    "\n",
    "train_ds = image_dataset_from_directory(\n",
    "    dir_name,\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    subset=\"training\",\n",
    "    validation_split=0.2,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "val_ds = image_dataset_from_directory(\n",
    "    dir_name,\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    subset=\"validation\",\n",
    "    validation_split=0.2,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Ajout d'optimisation : mise en cache et préchargement\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4cf3aa2-a4e4-42e3-bc5d-d01bdf591987",
   "metadata": {},
   "source": [
    "## Version custom de LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "951734a6-e63a-44de-ad43-54d91ed6d903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1742035354.272792   23151 cuda_dnn.cc:529] Loaded cuDNN version 90800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 185ms/step - accuracy: 0.3885 - loss: 1.2685 - val_accuracy: 0.4460 - val_loss: 1.0064 - learning_rate: 0.0010\n",
      "Epoch 2/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 120ms/step - accuracy: 0.4830 - loss: 1.0089 - val_accuracy: 0.4102 - val_loss: 1.1034 - learning_rate: 0.0010\n",
      "Epoch 3/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.5188 - loss: 0.9905 - val_accuracy: 0.4971 - val_loss: 0.9608 - learning_rate: 0.0010\n",
      "Epoch 4/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 120ms/step - accuracy: 0.5532 - loss: 0.9435 - val_accuracy: 0.5679 - val_loss: 0.9373 - learning_rate: 0.0010\n",
      "Epoch 5/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 122ms/step - accuracy: 0.5749 - loss: 0.9206 - val_accuracy: 0.5358 - val_loss: 0.9362 - learning_rate: 0.0010\n",
      "Epoch 6/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 124ms/step - accuracy: 0.5869 - loss: 0.9005 - val_accuracy: 0.5248 - val_loss: 0.9476 - learning_rate: 0.0010\n",
      "Epoch 7/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 120ms/step - accuracy: 0.5780 - loss: 0.9131 - val_accuracy: 0.5810 - val_loss: 0.8735 - learning_rate: 0.0010\n",
      "Epoch 8/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 121ms/step - accuracy: 0.6017 - loss: 0.8613 - val_accuracy: 0.5898 - val_loss: 0.8712 - learning_rate: 0.0010\n",
      "Epoch 9/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.5980 - loss: 0.8540 - val_accuracy: 0.5650 - val_loss: 0.8901 - learning_rate: 0.0010\n",
      "Epoch 10/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 120ms/step - accuracy: 0.5995 - loss: 0.8602 - val_accuracy: 0.5956 - val_loss: 0.8522 - learning_rate: 0.0010\n",
      "Epoch 11/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 126ms/step - accuracy: 0.6229 - loss: 0.8388 - val_accuracy: 0.6175 - val_loss: 0.8322 - learning_rate: 0.0010\n",
      "Epoch 12/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 122ms/step - accuracy: 0.6316 - loss: 0.8210 - val_accuracy: 0.6124 - val_loss: 0.8324 - learning_rate: 0.0010\n",
      "Epoch 13/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 123ms/step - accuracy: 0.6412 - loss: 0.8168 - val_accuracy: 0.6255 - val_loss: 0.8275 - learning_rate: 0.0010\n",
      "Epoch 14/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 124ms/step - accuracy: 0.6377 - loss: 0.8019 - val_accuracy: 0.6409 - val_loss: 0.8379 - learning_rate: 0.0010\n",
      "Epoch 15/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 82ms/step - accuracy: 0.6442 - loss: 0.7950 - val_accuracy: 0.6474 - val_loss: 0.8043 - learning_rate: 5.0000e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 131ms/step - accuracy: 0.6533 - loss: 0.7698 - val_accuracy: 0.6139 - val_loss: 0.8350 - learning_rate: 5.0000e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 125ms/step - accuracy: 0.6507 - loss: 0.7908 - val_accuracy: 0.6416 - val_loss: 0.8083 - learning_rate: 5.0000e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 126ms/step - accuracy: 0.6586 - loss: 0.7682 - val_accuracy: 0.6511 - val_loss: 0.8051 - learning_rate: 5.0000e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 123ms/step - accuracy: 0.6599 - loss: 0.7628 - val_accuracy: 0.6482 - val_loss: 0.7951 - learning_rate: 5.0000e-04\n",
      "Epoch 20/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 127ms/step - accuracy: 0.6646 - loss: 0.7591 - val_accuracy: 0.6467 - val_loss: 0.8065 - learning_rate: 5.0000e-04\n",
      "Epoch 21/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 82ms/step - accuracy: 0.6598 - loss: 0.7587 - val_accuracy: 0.6526 - val_loss: 0.7828 - learning_rate: 2.5000e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 123ms/step - accuracy: 0.6684 - loss: 0.7503 - val_accuracy: 0.6489 - val_loss: 0.7828 - learning_rate: 2.5000e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 126ms/step - accuracy: 0.6699 - loss: 0.7489 - val_accuracy: 0.6555 - val_loss: 0.7939 - learning_rate: 2.5000e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 125ms/step - accuracy: 0.6697 - loss: 0.7503 - val_accuracy: 0.6613 - val_loss: 0.7735 - learning_rate: 2.5000e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 124ms/step - accuracy: 0.6698 - loss: 0.7437 - val_accuracy: 0.6496 - val_loss: 0.7847 - learning_rate: 2.5000e-04\n",
      "Epoch 26/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 124ms/step - accuracy: 0.6648 - loss: 0.7362 - val_accuracy: 0.6613 - val_loss: 0.7657 - learning_rate: 2.5000e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - accuracy: 0.6772 - loss: 0.7383 - val_accuracy: 0.6701 - val_loss: 0.7827 - learning_rate: 2.5000e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 124ms/step - accuracy: 0.6809 - loss: 0.7393 - val_accuracy: 0.6774 - val_loss: 0.7559 - learning_rate: 2.5000e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 119ms/step - accuracy: 0.6820 - loss: 0.7262 - val_accuracy: 0.6445 - val_loss: 0.7993 - learning_rate: 2.5000e-04\n",
      "Epoch 30/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 122ms/step - accuracy: 0.6736 - loss: 0.7340 - val_accuracy: 0.6650 - val_loss: 0.7572 - learning_rate: 1.2500e-04\n"
     ]
    }
   ],
   "source": [
    "###  Architecture du model ###\n",
    "inputs = Input(shape=(224, 224, 3))\n",
    "\n",
    "# Data augmentation\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomFlip(\"horizontal\"),\n",
    "    tf.keras.layers.RandomRotation(0.2),\n",
    "    tf.keras.layers.RandomZoom(0.2),\n",
    "    tf.keras.layers.RandomContrast(0.2),\n",
    "])\n",
    "\n",
    "# Extraction des caractéristqiues\n",
    "x = data_augmentation(inputs)\n",
    "# Normalisation \n",
    "x = Rescaling(1./255)(x) \n",
    "\n",
    "# Première couche de convolution\n",
    "x = Conv2D(\n",
    "    filters=30,                    \n",
    "    kernel_size=(5, 5),            \n",
    "    padding='valid',               \n",
    "    activation='relu',            \n",
    ")(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2),)(x)\n",
    "x = Dropout(0,2)(x)\n",
    "\n",
    "# Deuxième couche de convolution\n",
    "x = Conv2D(\n",
    "    filters=16,                    \n",
    "    kernel_size=(5, 5),            \n",
    "    padding='valid',               \n",
    "    activation='relu',            \n",
    ")(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2),)(x)\n",
    "x = Dropout(0,2)(x)\n",
    "\n",
    "# Applatissement \n",
    "x = Flatten()(x)\n",
    "\n",
    "# Couches dense pour la prédiction \n",
    "dense_128 = Dense(\n",
    "    units=128,\n",
    "    activation='relu',\n",
    ")\n",
    "\n",
    "# Couche de sortie\n",
    "outputs = Dense(\n",
    "    units=3,\n",
    "    activation='softmax',\n",
    ")(x)\n",
    "\n",
    "reduce_learning_rate = ReduceLROnPlateau(\n",
    "                                    monitor=\"val_loss\",\n",
    "                                    patience=3,\n",
    "                                    min_delta=0.01,\n",
    "                                    factor=0.5, \n",
    "                                    cooldown=4)\n",
    "\n",
    "model_lenet = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model_lenet.compile(\n",
    "    loss='sparse_categorical_crossentropy',  \n",
    "    optimizer=\"adam\",                 \n",
    "    metrics=['accuracy'])             \n",
    "\n",
    "model_lenet_history = model_lenet.fit(train_ds,           # données\n",
    "                           validation_data=val_ds,\n",
    "                           epochs=30,\n",
    "                           callbacks=[reduce_learning_rate])             # taille des batchs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d994c3-7f05-46ea-8c10-70b7c06aa5df",
   "metadata": {},
   "source": [
    "## Analyse de l'entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69963274-edda-436b-8c5b-918476e8e1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_results(model_history, model_name):\n",
    "    # Récupérer les données d'entraînement et de validation\n",
    "    train_loss = model_history.history[\"loss\"]\n",
    "    val_loss = model_history.history[\"val_loss\"]\n",
    "    train_accuracy =  model_history.history[\"accuracy\"]\n",
    "    val_accuracy = model_history.history[\"val_accuracy\"]\n",
    "    \n",
    "    plt.figure(figsize=(20, 8))\n",
    "    \n",
    "    # Tracer la perte\n",
    "    plt.subplot(121)\n",
    "    plt.plot(train_loss)\n",
    "    plt.plot(val_loss)\n",
    "    plt.title(model_name + \": Perte d'entraînement et de validation\")\n",
    "    plt.ylabel('Perte ')\n",
    "    plt.xlabel('Époque')\n",
    "    plt.legend(['Entraînement', 'Validation'], loc='best')\n",
    "    \n",
    "    # Tracer l'erreur absolue moyenne (MAE)\n",
    "    plt.subplot(122)\n",
    "    plt.plot(train_accuracy)\n",
    "    plt.plot(val_accuracy)\n",
    "    plt.title(model_name+': Accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Époque')\n",
    "    plt.legend(['Entraînement', 'Validation'], loc='best')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# modèle LeNet\n",
    "val_loss, val_accuracy = model_lenet.evaluate(val_ds)\n",
    "print(f\"Précision de validation finale: {val_accuracy:.4f}\")\n",
    "display_results(model_lenet_history, \"LeNet\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ab9f4a-5132-444a-b23f-dde239cbb64b",
   "metadata": {},
   "source": [
    "## Analyse de la performance par classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c96a90e-c084-4653-a111-fd2f90e34159",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 1. Générer des prédictions sur l'ensemble de validation\n",
    "# Prévoir les classes pour tous les échantillons de validation\n",
    "predictions = []\n",
    "labels = []\n",
    "\n",
    "# Récupérer toutes les étiquettes et prédictions\n",
    "for images, true_labels in val_ds:\n",
    "    pred = model.predict(images)\n",
    "    pred_classes = np.argmax(pred, axis=1)\n",
    "    \n",
    "    predictions.extend(pred_classes)\n",
    "    labels.extend(true_labels.numpy())\n",
    "\n",
    "# Convertir en arrays numpy\n",
    "predictions = np.array(predictions)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# 2. Créer et afficher la matrice de confusion\n",
    "cm = confusion_matrix(labels, predictions)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Classe 0', 'Classe 1', 'Classe 2'],\n",
    "            yticklabels=['Classe 0', 'Classe 1', 'Classe 2'])\n",
    "plt.xlabel('Prédiction')\n",
    "plt.ylabel('Réalité')\n",
    "plt.title('Matrice de confusion')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
