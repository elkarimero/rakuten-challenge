{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bb8cfd5-9bef-44de-a925-bf39bcf2c5b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/karim/SEP24_CDS_Rakuten/env/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
      "120 fits failed out of a total of 360.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "120 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/karim/SEP24_CDS_Rakuten/env/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/karim/SEP24_CDS_Rakuten/env/lib/python3.12/site-packages/sklearn/base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/karim/SEP24_CDS_Rakuten/env/lib/python3.12/site-packages/sklearn/pipeline.py\", line 654, in fit\n",
      "    Xt = self._fit(X, y, routed_params, raw_params=params)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/karim/SEP24_CDS_Rakuten/env/lib/python3.12/site-packages/sklearn/pipeline.py\", line 588, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/karim/SEP24_CDS_Rakuten/env/lib/python3.12/site-packages/joblib/memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/karim/SEP24_CDS_Rakuten/env/lib/python3.12/site-packages/sklearn/pipeline.py\", line 1551, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/karim/SEP24_CDS_Rakuten/env/lib/python3.12/site-packages/sklearn/feature_extraction/text.py\", line 2104, in fit_transform\n",
      "    X = super().fit_transform(raw_documents)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/karim/SEP24_CDS_Rakuten/env/lib/python3.12/site-packages/sklearn/base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/karim/SEP24_CDS_Rakuten/env/lib/python3.12/site-packages/sklearn/feature_extraction/text.py\", line 1358, in fit_transform\n",
      "    self._validate_ngram_range()\n",
      "  File \"/home/karim/SEP24_CDS_Rakuten/env/lib/python3.12/site-packages/sklearn/feature_extraction/text.py\", line 508, in _validate_ngram_range\n",
      "    min_n, max_m = self.ngram_range\n",
      "    ^^^^^^^^^^^^\n",
      "ValueError: too many values to unpack (expected 2)\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/karim/SEP24_CDS_Rakuten/env/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [0.73940603 0.73641718        nan 0.73973189 0.73584029        nan\n",
      " 0.74368586 0.74405768        nan 0.74028017 0.74412986        nan\n",
      " 0.74325653 0.74827706        nan 0.74028017 0.74497995        nan\n",
      " 0.74176775 0.7372541         nan 0.74028017 0.74497995        nan\n",
      " 0.7471849  0.74083573        nan 0.74836686 0.74075099        nan\n",
      " 0.75660188 0.75122608        nan 0.7491515  0.75156523        nan\n",
      " 0.7606301  0.76078034        nan 0.7491515  0.75231684        nan\n",
      " 0.75946211 0.76206295        nan 0.7491515  0.75231684        nan\n",
      " 0.73729287 0.7294547         nan 0.73842622 0.72881628        nan\n",
      " 0.75105897 0.74086665        nan 0.74163031 0.74353437        nan\n",
      " 0.75606251 0.75265628        nan 0.74163031 0.74650086        nan\n",
      " 0.76008429 0.76550557        nan 0.74163031 0.74650086        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "les meilleurs paramètres sont {'clf__C': 5, 'clf__class_weight': 'balanced', 'clf__kernel': 'linear', 'tfidf__max_features': None, 'tfidf__min_df': 1, 'tfidf__ngram_range': (1, 2), 'tfidf__norm': 'l2', 'tfidf__sublinear_tf': True}\n",
      "le meilleur score obtenu est  0.7655055724007791\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Chargement des données\n",
    "df_path = '../../data/processed/df_avec_categorie_part3_traduit.csv'\n",
    "df = pd.read_csv(df_path)\n",
    "\n",
    "# création de la colonne 'text' à partir de 'trad' ou 'truncated'\n",
    "df['text'] = df.apply(lambda row: row['trad'] if not pd.isna(row['trad']) else row['truncated'], axis=1)\n",
    "\n",
    "# Vectorisation TF-IDF\n",
    "#vectorizer = TfidfVectorizer()\n",
    "#X = vectorizer.fit_transform(df['text'])\n",
    "X = df['text']\n",
    "y = df['category_name']\n",
    "\n",
    "# Split train/test stratifié pour conserver les proportions des classes\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Création du pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', svm.SVC(class_weight='balanced', random_state=42))\n",
    "])\n",
    "\n",
    "# Définition des paramètres à optimiser\n",
    "param_grid = {\n",
    "    # Paramètres TF-IDF\n",
    "    'tfidf__min_df': [1, 5],            # Ignorer les termes qui apparaissent dans moins de x documents\n",
    "    #'tfidf__max_df': [0.6, 0.8, 0.90],       # Ignorer les termes qui apparaissent dans plus de x% des documents\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2), (1, 2, 3)],  # Unigrammes ou uni+bigrammes\n",
    "    'tfidf__max_features': [10000, 20000, 40000, None], # Limiter la taille du vocabulaire\n",
    "    'tfidf__sublinear_tf': [True],           # Appliquer une mise à l'échelle log(1+tf) Presque toujours bénéfique pour de longs textes\n",
    "    'tfidf__norm': ['l2'],                   # Normalisation des vecteurs (L2 est généralement le meilleur pour SVM)\n",
    "    \n",
    "    # Paramètres SVM \n",
    "    'clf__kernel': ['linear'],               # Linéaire est souvent meilleur pour du texte et plus rapide\n",
    "    'clf__C': [0.5, 1, 5],                   # Plage ciblée pour équilibrer généralisation/surapprentissage\n",
    "    'clf__class_weight': ['balanced'],       # Gestion des classes déséquilibrées\n",
    "}\n",
    "\n",
    "# Configuration de la recherche par grille\n",
    "gridsearch = GridSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,                    # Validation croisée à 5 plis\n",
    "    scoring='f1_weighted',   # Métrique pertinente pour les classes déséquilibrées\n",
    "    n_jobs=-1              # Utiliser tous les cœurs disponibles\n",
    ")\n",
    "\n",
    "gridsearch.fit(X,y)\n",
    "\n",
    "print(\"les meilleurs paramètres sont\", gridsearch.best_params_)\n",
    "print(\"le meilleur score obtenu est \", gridsearch.best_score_)\n",
    "\n",
    "#les meilleurs paramètres sont {'C': 10, 'class_weight': 'balanced', 'kernel': 'linear'}\n",
    "#le meilleur score obtenu est  0.7450774234905061\n",
    "\n",
    "#les meilleurs paramètres sont \n",
    "#{'clf__C': 1, 'clf__class_weight': 'balanced', 'clf__kernel': 'linear', 'tfidf__max_df': 0.6, 'tfidf__max_features': 40000, 'tfidf__min_df': 5, 'tfidf__ngram_range': (1, 2), 'tfidf__norm': 'l2', 'tfidf__sublinear_tf': True}\n",
    "#le meilleur score obtenu est  0.7523168429429458\n",
    "\n",
    "#les meilleurs paramètres sont {'clf__C': 5, 'clf__class_weight': 'balanced', 'clf__kernel': 'linear', 'tfidf__max_features': None, 'tfidf__min_df': 1, 'tfidf__ngram_range': (1, 2), 'tfidf__norm': 'l2', 'tfidf__sublinear_tf': True}\n",
    "#le meilleur score obtenu est  0.7655055724007791\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86604cd-7dfb-4164-a6b5-bb766dad804d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import BayesSearchCV\n",
    "parameters = {'kernel' : ['linear', 'rbf'], 'C' : (0.1, 10.0, 'log-uniform'), class_weight: 'balanced'}\n",
    "\n",
    "svc_model = svm.SVC()\n",
    "bayes_search = BayesSearchCV(svc_model, parameters,  n_iter = 20)\n",
    "bayes_search.fit(X,y)\n",
    "\n",
    "print(\"les meilleurs paramètres sont\", bayes_search.best_params_)\n",
    "print(\"le meilleur score obtenu est \", bayes_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cda74d5c-1a21-44d7-a60e-7e7b2a12b5c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['30', 'aa', 'aaa', ..., 'île', 'œil', 'œufs'],\n",
       "      shape=(73642,), dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Chargement des données\n",
    "df_path = '../../data/processed/df_avec_categorie_part3_traduit.csv'\n",
    "df = pd.read_csv(df_path)\n",
    "\n",
    "# création de la colonne 'text' à partir de 'trad' ou 'truncated'\n",
    "df['text'] = df.apply(lambda row: row['trad'] if not pd.isna(row['trad']) else row['truncated'], axis=1)\n",
    "\n",
    "# Vectorisation TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(df['text'])\n",
    "y = df['category_name']\n",
    "\n",
    "vectorizer.get_feature_names_out()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
