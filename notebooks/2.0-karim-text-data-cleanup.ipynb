{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "aff29242-bf51-4b38-8dc6-0db624d1d07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    " \n",
    "X_train = pd.read_csv(\"../data/raw/X_train.csv\", sep=\",\",index_col=0)\n",
    "Y_train = pd.read_csv(\"../data/raw/Y_train.csv\", sep=\",\",index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "476dd79f-0708-43fe-9ddf-952934d52c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il y a 861 lignes où designation et description contiennent les mêmes informations\n",
      "Il y a 0 lignes où designation et description contiennent les mêmes informations après nettoyage\n"
     ]
    }
   ],
   "source": [
    "# SUPPRESSION DES DOUBLONS EN COLONNE\n",
    "\n",
    "# D'abord on normalise le texte pour éviter certains pb lors de l'analyse de doublong (sensibilité à la case, encodage, espace en début/fin ...)\n",
    "def clean_text(text):\n",
    "    if isinstance(text, str):            # Si le texte est une chaîne de caractères,\n",
    "        #text = unidecode(text)          # Remplace les accents par des lettres sans accent\n",
    "        text = text.lower()               # Met le texte en minuscule\n",
    "        text = text.strip()              # supprime les espaces en début/fin de chaine\n",
    "        text = ' '.join(text.split())    # supprime les espaces inutiles\n",
    "        return text\n",
    "    return text\n",
    "    \n",
    "X_train[\"designation\"] = X_train[\"designation\"].map(clean_text)\n",
    "X_train[\"description\"] = X_train['description'].map(clean_text)\n",
    "\n",
    "\n",
    "# Avant de concaténer Designation et Description, on vérifie qu'il n'y a pas la même chose dans ces deux colonnes\n",
    "nb_duplicates = (X_train[\"designation\"] == X_train[\"description\"]).sum()\n",
    "print(\"Il y a\",nb_duplicates,\"lignes où designation et description contiennent les mêmes informations\")\n",
    "\n",
    "# On remplace alors la description par une chaine de caractère vide pour préparer la concaténation\n",
    "X_train.loc[X_train[\"designation\"] == X_train[\"description\"], \"description\"] = \"\"\n",
    "\n",
    "# On vérifie que le nettoyage a fonctionné\n",
    "nb_duplicates_ac = (X_train[\"designation\"] == X_train[\"description\"]).sum()\n",
    "print(\"Il y a\",nb_duplicates_ac,\"lignes où designation et description contiennent les mêmes informations après nettoyage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8162c8cb-5ac8-4bb9-97c3-6cf063936b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de NaN dans la colonne designation: 0\n",
      "Nombre de NaN dans la colonne description: 29800 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>productid</th>\n",
       "      <th>imageid</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3804725264</td>\n",
       "      <td>1263597046</td>\n",
       "      <td>olivia: personalisiertes notizbuch / 150 seite...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>436067568</td>\n",
       "      <td>1008141237</td>\n",
       "      <td>journal des arts (le) n° 133 du 28/09/2001 - l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201115110</td>\n",
       "      <td>938777978</td>\n",
       "      <td>grand stylet ergonomique bleu gamepad nintendo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50418756</td>\n",
       "      <td>457047496</td>\n",
       "      <td>peluche donald - europe - disneyland 2000 (mar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>278535884</td>\n",
       "      <td>1077757786</td>\n",
       "      <td>la guerre des tuques luc a des id&amp;eacute;es de...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    productid     imageid                                               text\n",
       "0  3804725264  1263597046  olivia: personalisiertes notizbuch / 150 seite...\n",
       "1   436067568  1008141237  journal des arts (le) n° 133 du 28/09/2001 - l...\n",
       "2   201115110   938777978  grand stylet ergonomique bleu gamepad nintendo...\n",
       "3    50418756   457047496  peluche donald - europe - disneyland 2000 (mar...\n",
       "4   278535884  1077757786  la guerre des tuques luc a des id&eacute;es de..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# CONCATENATION DES COLONNEs DESIGNATION ET DESCRIPTION\n",
    "\n",
    "print(\"Nombre de NaN dans la colonne designation:\", X_train[\"designation\"].isna().sum())\n",
    "print(\"Nombre de NaN dans la colonne description:\", X_train[\"description\"].isna().sum(),\"\\n\")\n",
    "\n",
    "# On remplace les NaN de la colonne \"description\" par une chaine vide pour que la concaténation fonctionne\n",
    "# et concatène \"designation\" et \"description\" dans une nouvelle colonne full description\n",
    "# puis on supprime les éventuels espace de fin inutile\n",
    "X_train[\"text\"] = X_train[[\"designation\", \"description\"]].fillna(\"\").agg(' '.join, axis=1)\n",
    "X_train[\"text\"] = X_train[\"text\"].str.strip()\n",
    "\n",
    "# Suppression des colonnes inutiles\n",
    "X_train = X_train.drop(columns=['designation','description'])\n",
    "display(X_train.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7dbc1ab0-89a4-401d-9f65-d46ffcc833c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "il existe 1447 doublons de texte\n",
      "suppression des 1447 doublons\n"
     ]
    }
   ],
   "source": [
    "# On regarde si on a des doublons\n",
    "nb_duplicated_text = X_train['text'].duplicated().sum()\n",
    "print(\"il existe\", nb_duplicated_text, \"doublons de texte\")\n",
    "\n",
    "# Suppression des doublons en fonction de la colonne fusionnée\n",
    "X_train = X_train.drop_duplicates(subset=['text'])\n",
    "print(\"suppression des\",nb_duplicated_text,\"doublons\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2250c1-f7ff-4cfd-9e29-bed1f32e642c",
   "metadata": {},
   "source": [
    "On remarque en étudiant le contenu du dataset visuellement que celui-ci semble contenir:\n",
    "* des balise html \n",
    "* des entités html (&amp, &nbsp,&lt, &gt ...)\n",
    "\n",
    "Ces balises et ces entités ne sont pas toujours bien formées (ex: < br >, & nbsp ...)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "17ec7ec0-b9db-46e9-b062-d9ef7b7fd552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            \n",
       "& patcher ;      2\n",
       "& amp ;          1\n",
       "& hygiénique;    1\n",
       "& nbsp;          1\n",
       "& play ;         1\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# traitement des entités html (type &amp, &quot, etc)\n",
    "\n",
    "import html\n",
    "\n",
    "X_train[\"text\"] = X_train[\"text\"].apply(html.unescape)\n",
    "\n",
    "# On va essayer d'identifier les cas les plus fréquents d'entitée html mal formée\n",
    "df_html = X_train[\"text\"].str.extract(r\"(&\\s*\\w+\\s*;)\").dropna()\n",
    "display(df_html.value_counts().head(30))\n",
    "\n",
    "# Dictionnaire des entités malformées à corriger\n",
    "html_entities = {\n",
    "    \"& amp;\": \"&amp;\",\n",
    "    \"& nbsp;\": \"&nbsp;\",\n",
    "    \"& lt;\": \"&lt;\",\n",
    "    \"& gt;\": \"&gt;\",\n",
    "    \"& nbsp ;\": \"&nbsp;\",\n",
    "    \"& amp ; \": \"&amp;\",\n",
    "    \"& gt ;\": \"&gt;\",\n",
    "    \"& quot;\": \"&quot;\"\n",
    "}\n",
    "\n",
    "# Remplacer toutes les entités malformées en une seule passe\n",
    "for incorrect, correct in html_entities.items():\n",
    "    X_train[\"text\"] = X_train[\"text\"].str.replace(incorrect, correct, regex=False)\n",
    "\n",
    "# on unescape de nouveau les entités pour gérer les cas corrigés\n",
    "X_train[\"text\"] = X_train[\"text\"].apply(html.unescape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "866c0786-41ab-49b6-a4a1-4d6b693a6805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nous avons identifié 405 balises html uniques présentent dans les descriptions produit\n"
     ]
    }
   ],
   "source": [
    "# TRAITEMENT DES BALISES HTML (type <b>, </p>, etc)\n",
    "\n",
    "# Importation de la bibliothèque \"Regular Expression\"\n",
    "import re     \n",
    "\n",
    "# Fonction qui identifie tout ce qui est délimité par < >\n",
    "def extraction_balises(texte):\n",
    "    return re.findall(r\"<[^>]+>\", str(texte))        \n",
    "\n",
    "# Création d'une liste d'éléments uniques\n",
    "balises = set()                                   \n",
    "X_train[\"text\"].apply(lambda x: balises.update(extraction_balises(x)))\n",
    "\n",
    "print(\"Nous avons identifié\",len(balises),\"balises html uniques présentent dans les descriptions produit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30546807-2f06-4e49-97ff-3294173a6e30",
   "metadata": {},
   "source": [
    "En jettant consultant la liste des balises identifiées, on observe \n",
    "* qu'il n'y a pas que des balises HTML. Il y a également beaucoup de texte délimité par des doubles chevrons, par exemple : << brouillard >>, <>, ou encore <>\n",
    "* qu'il y a des balises html mal formée < br >, < /p>\n",
    "* qu'il y a des commentaires html <!-- -->\n",
    "\n",
    "Si on veut nettoyer efficacement en limitant la perte d'information, je pense qu'il faut d'abord gérer à part les cas comme << brouillard >> en supprimant les doubles chevrons et en conservant le texte.\n",
    "puis utiliser une regex assez large pour supprimer tout contenu compris entre 2 chevrons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "601ac681-3aba-4dd6-a70b-0b86b76e0ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nous avons identifier 0 balises html uniques restant\n"
     ]
    }
   ],
   "source": [
    "# suppression des doubles chevrons\n",
    "X_train[\"text\"] = X_train[\"text\"].str.replace(\"<<\", \"\").str.replace(\">>\", \"\")\n",
    "\n",
    "# on supprime les balises html quelles soient bien ou mal formées\n",
    "X_train['text'] = X_train['text'].str.replace(r'<[^>]*>', '', regex=True)\n",
    "\n",
    "# on vérifie qu'il n'y a plus de balise html\n",
    "balises2 = set()                                   \n",
    "X_train[\"text\"].apply(lambda x: balises2.update(extraction_balises(x)))\n",
    "\n",
    "print(\"Nous avons identifier\",len(balises2),\"balises html uniques restant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b0688e00-a4fb-426e-a7f9-4ff17c2bf9d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Après traitement du html on se retrouve avec 0 doublon\n"
     ]
    }
   ],
   "source": [
    "duplicated = X_train[\"text\"].duplicated().sum()\n",
    "\n",
    "print(\"Après traitement du html on se retrouve avec\",duplicated,\"doublon\")\n",
    "\n",
    "X_train = X_train.drop_duplicates(subset=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "05a2638e-434c-4a47-9029-1623650c1116",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sauvegarde du dataframe clean dans un fichier\n",
    "X_train.to_csv(\"../data/interim/X_train.csv\", index = False)\n",
    "Y_train.loc[Y_train.index.isin(X_train.index)].to_csv(\"../data/interim/Y_train.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
