{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports des utilitaires pour le nettoyages de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import os\n",
    "\n",
    "import random\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set_theme (style = \"whitegrid\", palette= \"pastel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"X_test_update.csv\", sep = ',')\n",
    "train = pd.read_csv(\"X_train_update.csv\", sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il y a 179 lignes où designation et description contiennent les mêmes informations\n"
     ]
    }
   ],
   "source": [
    "# SUPPRESSION DES DOUBLONS EN COLONNE\n",
    "\n",
    "# Avant de concaténer Designation et Description, on vérifie qu'il n'y a pas la même chose dans ces deux colonnes\n",
    "nombre_lignes = (train[\"designation\"] == train[\"description\"]).sum()\n",
    "print(\"Il y a\",nombre_lignes,\"lignes où designation et description contiennent les mêmes informations\")\n",
    "\n",
    "# On remplace alors la description par une chaine de caractère vide pour préparer la concaténation\n",
    "train.loc[train[\"designation\"] == train[\"description\"], \"description\"] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge des colonnes designation et description dans une nouvelles colonnes \"merges\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        productid     imageid  \\\n",
      "0      3804725264  1263597046   \n",
      "1       436067568  1008141237   \n",
      "2       201115110   938777978   \n",
      "3        50418756   457047496   \n",
      "4       278535884  1077757786   \n",
      "...           ...         ...   \n",
      "84911   206719094   941495734   \n",
      "84912  3065095706  1188462883   \n",
      "84913   440707564  1009325617   \n",
      "84914  3942400296  1267353403   \n",
      "84915    57203227   684671297   \n",
      "\n",
      "                                                  merged  \n",
      "0      Olivia: Personalisiertes Notizbuch / 150 Seite...  \n",
      "1      Journal Des Arts (Le) N° 133 Du 28/09/2001 - L...  \n",
      "2      Grand Stylet Ergonomique Bleu Gamepad Nintendo...  \n",
      "3      Peluche Donald - Europe - Disneyland 2000 (Mar...  \n",
      "4      La Guerre Des Tuques Luc a des id&eacute;es de...  \n",
      "...                                                  ...  \n",
      "84911                        The Sims [ Import Anglais ]  \n",
      "84912  Kit piscine acier NEVADA déco pierre Ø 3.50m x...  \n",
      "84913  Journal Officiel De La Republique Francaise N°...  \n",
      "84914  Table Basse Bois De Récupération Massif Base B...  \n",
      "84915  Gomme De Collection 2 Gommes Pinguin Glace Ver...  \n",
      "\n",
      "[83501 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "train_merge = train\n",
    "\n",
    "# Fusion des colonnes 'designation' et 'description'\n",
    "train_merge['merged'] = pd.concat([\n",
    "    train_merge['designation'].fillna(''), \n",
    "    train_merge['description'].fillna('')\n",
    "], axis=1).apply(' '.join, axis=1)\n",
    "\n",
    "# Nettoyage des espaces inutiles dans la colonne fusionnée\n",
    "train_merge['merged'] = train_merge['merged'].str.strip()\n",
    "\n",
    "# Suppression des doublons en fonction de la colonne fusionnée\n",
    "train_merge = train_merge.drop_duplicates(subset=['merged'])\n",
    "\n",
    "train_merge= train_merge.drop(columns=['designation','description', \"Unnamed: 0\"])\n",
    "\n",
    "# Résultat final\n",
    "print(train_merge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On vérifie ensuite s'il existe des doublons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aucun doublon trouvé dans la colonne 'merged'.\n"
     ]
    }
   ],
   "source": [
    "# Vérifier si des doublons existent dans la colonne 'merged'\n",
    "duplicates_exist = train_merge['merged'].duplicated().any()\n",
    "\n",
    "# Afficher le résultat\n",
    "if duplicates_exist:\n",
    "    print(\"Il existe des doublons dans la colonne 'merged'.\")\n",
    "    # Afficher les lignes dupliquées\n",
    "    print(\"Voici les doublons :\")\n",
    "    print(train_merge[train_merge['merged'].duplicated(keep=False)])\n",
    "else:\n",
    "    print(\"Aucun doublon trouvé dans la colonne 'merged'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans la colonnes \"merged\" on regarde la fréquence des mots "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les 10 mots les plus fréquents :\n",
      "de: 400617\n",
      "la: 152722\n",
      "et: 149260\n",
      "pour: 96356\n",
      "en: 91686\n",
      "le: 89042\n",
      "les: 77115\n",
      "x: 73618\n",
      "des: 54567\n",
      "un: 50470\n",
      "     Word  Frequency\n",
      "55     de     400617\n",
      "31     la     152722\n",
      "19     et     149260\n",
      "59   pour      96356\n",
      "105    en      91686\n",
      "13     le      89042\n",
      "239   les      77115\n",
      "167     x      73618\n",
      "11    des      54567\n",
      "61     un      50470\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "# Concaténer toutes les lignes de la colonne 'merged' dans une seule chaîne\n",
    "all_text = \" \".join(train_merge['merged'].dropna())\n",
    "\n",
    "# Nettoyer le texte (enlever les caractères spéciaux, mettre en minuscule, etc.)\n",
    "cleaned_text = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", all_text.lower())\n",
    "\n",
    "# Diviser le texte en mots\n",
    "words = cleaned_text.split()\n",
    "\n",
    "# Calculer la fréquence des mots\n",
    "word_counts = Counter(words)\n",
    "\n",
    "# Afficher les 10 mots les plus fréquents\n",
    "print(\"Les 10 mots les plus fréquents :\")\n",
    "for word, count in word_counts.most_common(10):\n",
    "    print(f\"{word}: {count}\")\n",
    "\n",
    "# Convertir en DataFrame pour une visualisation tabulaire si nécessaire\n",
    "word_counts_df = pd.DataFrame(word_counts.items(), columns=['Word', 'Frequency']).sort_values(by='Frequency', ascending=False)\n",
    "\n",
    "# Afficher les 10 premiers mots\n",
    "print(word_counts_df.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>productid</th>\n",
       "      <th>imageid</th>\n",
       "      <th>merged</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3804725264</td>\n",
       "      <td>1263597046</td>\n",
       "      <td>olivia: personalisiertes notizbuch / 150 seite...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>436067568</td>\n",
       "      <td>1008141237</td>\n",
       "      <td>journal des arts (le) ndeg 133 du 28/09/2001 -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201115110</td>\n",
       "      <td>938777978</td>\n",
       "      <td>grand stylet ergonomique bleu gamepad nintendo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50418756</td>\n",
       "      <td>457047496</td>\n",
       "      <td>peluche donald - europe - disneyland 2000 (mar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>278535884</td>\n",
       "      <td>1077757786</td>\n",
       "      <td>la guerre des tuques luc a des id&amp;eacute;es de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5862738</td>\n",
       "      <td>393356830</td>\n",
       "      <td>afrique contemporaine ndeg 212 hiver 2004 - do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>91920807</td>\n",
       "      <td>907794536</td>\n",
       "      <td>christof e: bildungsprozessen auf der spur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>344240059</td>\n",
       "      <td>999581347</td>\n",
       "      <td>conquerant sept cahier couverture polypro 240 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4239126071</td>\n",
       "      <td>1325918866</td>\n",
       "      <td>puzzle scooby-doo avec poster 2x35 pieces</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3793572222</td>\n",
       "      <td>1245644185</td>\n",
       "      <td>tente pliante v3s5-pro pvc blanc - 3 x 4m50 - ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1915836983</td>\n",
       "      <td>1111840281</td>\n",
       "      <td>eames inspired sxw chair - pink - black the ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4127967621</td>\n",
       "      <td>1295816984</td>\n",
       "      <td>fauteuil chesterfield brenton 100% cuir de buf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3287127001</td>\n",
       "      <td>1204199842</td>\n",
       "      <td>peaceable kingdom wheres bear? the hide and fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1882164320</td>\n",
       "      <td>1109088140</td>\n",
       "      <td>paire de voilages imprimes fantaisie paire de ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4108914287</td>\n",
       "      <td>1292441752</td>\n",
       "      <td>matelas memoire de forme 180x200 x 20 cm tres ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3718150116</td>\n",
       "      <td>1237257586</td>\n",
       "      <td>zenith pince agrafeuse 591 ndeg10 coloris noir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3735707499</td>\n",
       "      <td>1239242410</td>\n",
       "      <td>walter scott oeuvres completes tomes 3456 10 e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2666371748</td>\n",
       "      <td>1156191369</td>\n",
       "      <td>mod podge dishwasher safe gloss 8oz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>91015572</td>\n",
       "      <td>857195931</td>\n",
       "      <td>power rangers rouge force mystic figurine tran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>570628142</td>\n",
       "      <td>1027257229</td>\n",
       "      <td>monde illustre (le) ndeg 3083 du 20/01/1917 - ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3936362802</td>\n",
       "      <td>1268740880</td>\n",
       "      <td>kit de desinfection pour piscines enfants 20990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3228900895</td>\n",
       "      <td>1199384348</td>\n",
       "      <td>glitter beach barbie by barbie original barbie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1893048509</td>\n",
       "      <td>1110089245</td>\n",
       "      <td>le seigneur des anneaux figurine en plomb a pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>279822475</td>\n",
       "      <td>978593209</td>\n",
       "      <td>vehicule star wars a-ast5 vehicule vintage de ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3748203527</td>\n",
       "      <td>1240721678</td>\n",
       "      <td>mini wifi 720p camera drone rc quadcopter 24 g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>211334790</td>\n",
       "      <td>948608572</td>\n",
       "      <td>dsi + chargeur + sacoche + 12 jeux</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>4137059841</td>\n",
       "      <td>1297749086</td>\n",
       "      <td>modele de voiture 4pcs alliage metallique 1.9i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2536863974</td>\n",
       "      <td>1148154575</td>\n",
       "      <td>faber-castell lot de 3 crayons de couleur poly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>570663184</td>\n",
       "      <td>1027317460</td>\n",
       "      <td>univers (l') ndeg 249 du 12/09/1854 - france -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3226779852</td>\n",
       "      <td>1202890774</td>\n",
       "      <td>dragon ball super - bt3-070 - c-13 les premiss...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>4198487181</td>\n",
       "      <td>1313675704</td>\n",
       "      <td>lampe de lecture rechargeable led lampe de bea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>49132716</td>\n",
       "      <td>874730792</td>\n",
       "      <td>x-men 3 - the movie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>3079667218</td>\n",
       "      <td>1195260111</td>\n",
       "      <td>2 cagettes de rangement happy life - 40 x 30 c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>3817904723</td>\n",
       "      <td>1248853903</td>\n",
       "      <td>lindner 2365-2115ce coin case nera xl with 3 t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>4237073471</td>\n",
       "      <td>1324384878</td>\n",
       "      <td>the lord or the rings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>4211197055</td>\n",
       "      <td>1317753478</td>\n",
       "      <td>decoration de noel christmas snowman kitchen t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>3847254406</td>\n",
       "      <td>1264434293</td>\n",
       "      <td>30 spots encastrable orientable blanc avec gu1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>4007155304</td>\n",
       "      <td>1275613423</td>\n",
       "      <td>nouveau 01h20 echelle alloy mini pull back voi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>4012748163</td>\n",
       "      <td>1276344493</td>\n",
       "      <td>4pcs decor coussin independance style jeter co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>3147314797</td>\n",
       "      <td>1225887302</td>\n",
       "      <td>bouee gonflable river tube - oogarden bouee go...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     productid     imageid                                             merged\n",
       "0   3804725264  1263597046  olivia: personalisiertes notizbuch / 150 seite...\n",
       "1    436067568  1008141237  journal des arts (le) ndeg 133 du 28/09/2001 -...\n",
       "2    201115110   938777978  grand stylet ergonomique bleu gamepad nintendo...\n",
       "3     50418756   457047496  peluche donald - europe - disneyland 2000 (mar...\n",
       "4    278535884  1077757786  la guerre des tuques luc a des id&eacute;es de...\n",
       "5      5862738   393356830  afrique contemporaine ndeg 212 hiver 2004 - do...\n",
       "6     91920807   907794536         christof e: bildungsprozessen auf der spur\n",
       "7    344240059   999581347  conquerant sept cahier couverture polypro 240 ...\n",
       "8   4239126071  1325918866          puzzle scooby-doo avec poster 2x35 pieces\n",
       "9   3793572222  1245644185  tente pliante v3s5-pro pvc blanc - 3 x 4m50 - ...\n",
       "10  1915836983  1111840281  eames inspired sxw chair - pink - black the ti...\n",
       "11  4127967621  1295816984  fauteuil chesterfield brenton 100% cuir de buf...\n",
       "12  3287127001  1204199842  peaceable kingdom wheres bear? the hide and fi...\n",
       "13  1882164320  1109088140  paire de voilages imprimes fantaisie paire de ...\n",
       "14  4108914287  1292441752  matelas memoire de forme 180x200 x 20 cm tres ...\n",
       "15  3718150116  1237257586  zenith pince agrafeuse 591 ndeg10 coloris noir...\n",
       "16  3735707499  1239242410  walter scott oeuvres completes tomes 3456 10 e...\n",
       "17  2666371748  1156191369                mod podge dishwasher safe gloss 8oz\n",
       "18    91015572   857195931  power rangers rouge force mystic figurine tran...\n",
       "19   570628142  1027257229  monde illustre (le) ndeg 3083 du 20/01/1917 - ...\n",
       "20  3936362802  1268740880    kit de desinfection pour piscines enfants 20990\n",
       "21  3228900895  1199384348  glitter beach barbie by barbie original barbie...\n",
       "22  1893048509  1110089245  le seigneur des anneaux figurine en plomb a pe...\n",
       "23   279822475   978593209  vehicule star wars a-ast5 vehicule vintage de ...\n",
       "24  3748203527  1240721678  mini wifi 720p camera drone rc quadcopter 24 g...\n",
       "25   211334790   948608572                 dsi + chargeur + sacoche + 12 jeux\n",
       "26  4137059841  1297749086  modele de voiture 4pcs alliage metallique 1.9i...\n",
       "27  2536863974  1148154575  faber-castell lot de 3 crayons de couleur poly...\n",
       "28   570663184  1027317460  univers (l') ndeg 249 du 12/09/1854 - france -...\n",
       "29  3226779852  1202890774  dragon ball super - bt3-070 - c-13 les premiss...\n",
       "30  4198487181  1313675704  lampe de lecture rechargeable led lampe de bea...\n",
       "31    49132716   874730792                                x-men 3 - the movie\n",
       "32  3079667218  1195260111  2 cagettes de rangement happy life - 40 x 30 c...\n",
       "33  3817904723  1248853903  lindner 2365-2115ce coin case nera xl with 3 t...\n",
       "34  4237073471  1324384878                              the lord or the rings\n",
       "35  4211197055  1317753478  decoration de noel christmas snowman kitchen t...\n",
       "36  3847254406  1264434293  30 spots encastrable orientable blanc avec gu1...\n",
       "37  4007155304  1275613423  nouveau 01h20 echelle alloy mini pull back voi...\n",
       "38  4012748163  1276344493  4pcs decor coussin independance style jeter co...\n",
       "39  3147314797  1225887302  bouee gonflable river tube - oogarden bouee go..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# NORMALISATION DU TEXTE\n",
    "\n",
    "from unidecode import unidecode\n",
    "\n",
    "def clean_text(text):\n",
    "    if isinstance(text, str):            # Si le texte est une chaîne de caractères,\n",
    "        text = unidecode(text)             # Remplace les accents par des lettres sans accent\n",
    "        text = text.lower()                # Met le texte en minuscule\n",
    "        text = ' '.join(text.split())      # Remplace les espaces inutiles\n",
    "        return text\n",
    "    return text\n",
    "\n",
    "train_merge[\"merged\"] = train_merge['merged'].apply(clean_text)\n",
    "display(train_merge.head(40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nouveaux doublons supprimés : 38\n",
      "Il reste : 83463 lignes\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# NOUVEAU CONTRÔLE SUR LES DOUBLONS\n",
    "\n",
    "nb_lignes_avant = len(train_merge)\n",
    "train_merge = train_merge.drop_duplicates(subset=[\"merged\"])                 # On supprime les doublons en ne gardant que la première occurance \n",
    "\n",
    "nb_lignes_apres = len(train_merge)\n",
    "print(\"Nouveaux doublons supprimés :\", nb_lignes_avant - nb_lignes_apres)\n",
    "print(\"Il reste :\",nb_lignes_apres,\"lignes\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nous avons identifier 984 balises uniques\n"
     ]
    }
   ],
   "source": [
    "# TRAITEMENT DES BALISES HTML (type <b>, </p>, etc)\n",
    "\n",
    "# Importation de la bibliothèque \"Regular Expression\"\n",
    "import re \n",
    "\n",
    "\n",
    "# Fonction qui identifie tout ce qui est délimité par < >\n",
    "def extraction_balises(texte):\n",
    "    return re.findall(r\"<[^>]+>\", str(texte))     \n",
    "\n",
    "\n",
    "# Création d'une liste d'éléments uniques\n",
    "balises = set()                                   \n",
    "train_merge[\"merged\"].apply(lambda x: balises.update(extraction_balises(x)))\n",
    "\n",
    "\n",
    "# Création d'un dataframe et export Excel pour meilleur visibilité\n",
    "df_balises = pd.DataFrame(list(balises), columns=[\"Balises\"])\n",
    "df_balises[\"Balises\"].to_excel(\"fichier_balises.xlsx\", index=False)\n",
    "\n",
    "print(\"Nous avons identifier\",len(df_balises),\"balises uniques\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SUPPRESSION DES DOUBLES CHEVRONS\n",
    "train_merge[\"merged\"] = train_merge[\"merged\"].str.replace(\"<<\", \"\").str.replace(\">>\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il ne reste plus que 317 balises uniques après suppression des doubles chevrons délimitants du texte\n"
     ]
    }
   ],
   "source": [
    "# On relance le traitement des balises HTML\n",
    "\n",
    "balises = set()                                   \n",
    "train_merge[\"merged\"].apply(lambda x: balises.update(extraction_balises(x)))\n",
    "\n",
    "df_balises = pd.DataFrame(list(balises), columns=[\"Balises\"])\n",
    "df_balises[\"Balises\"].to_excel(\"fichier_balises.xlsx\", index=False)\n",
    "\n",
    "print(\"Il ne reste plus que\",len(df_balises),\"balises uniques après suppression des doubles chevrons délimitants du texte\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1350 entries, 62 to 84879\n",
      "Data columns (total 1 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   caractere  1350 non-null   object\n",
      "dtypes: object(1)\n",
      "memory usage: 21.1+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>caractere</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>&amp; creme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>&amp; 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>&amp; son</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>&amp; r2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>&amp; bunny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>&amp; engineering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>&amp; mortimer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>&amp; hal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>&amp; 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>&amp; gris</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         caractere\n",
       "62         & creme\n",
       "74             & 2\n",
       "96           & son\n",
       "196           & r2\n",
       "327        & bunny\n",
       "335  & engineering\n",
       "385     & mortimer\n",
       "416          & hal\n",
       "417            & 2\n",
       "446         & gris"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "caractere \n",
       "& 2           63\n",
       "& blanc       31\n",
       "& dragons     31\n",
       "& the         20\n",
       "& 3           19\n",
       "& decker      15\n",
       "& d           13\n",
       "& smart       12\n",
       "& ntsc        12\n",
       "& triphase    11\n",
       "& clear       10\n",
       "& noir         9\n",
       "& zoom         9\n",
       "& mavic        8\n",
       "& points       8\n",
       "& cadre        8\n",
       "& cie          8\n",
       "& vie          7\n",
       "& spice        7\n",
       "& stratton     7\n",
       "& leopard      7\n",
       "& piano        7\n",
       "& 4            7\n",
       "& magic        6\n",
       "& mrs          6\n",
       "& la           6\n",
       "& le           6\n",
       "& play         6\n",
       "& carreaux     6\n",
       "& girl         6\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_html = train_merge[\"merged\"].str.extract(r\"(&\\s\\w+)\")\n",
    "df_html = df_html.dropna()\n",
    "df_html.columns = ['caractere']\n",
    "\n",
    "display(df_html.info())\n",
    "print(\"\\n\")\n",
    "display(df_html.head(10))\n",
    "print(\"\\n\")\n",
    "display(df_html.value_counts().head(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valeurs manquantes avant nettoyage :\n",
      "productid    0\n",
      "imageid      0\n",
      "merged       0\n",
      "dtype: int64\n",
      "Types de données après nettoyage :\n",
      "productid     int64\n",
      "imageid       int64\n",
      "merged       object\n",
      "dtype: object\n",
      "DataFrame nettoyé :\n",
      "    productid     imageid                                             merged\n",
      "0  3804725264  1263597046  olivia: personalisiertes notizbuch / 150 seite...\n",
      "1   436067568  1008141237  journal des arts (le) ndeg 133 du 28/09/2001 -...\n",
      "2   201115110   938777978  grand stylet ergonomique bleu gamepad nintendo...\n",
      "3    50418756   457047496  peluche donald - europe - disneyland 2000 (mar...\n",
      "4   278535884  1077757786  la guerre des tuques luc a des id&eacute;es de...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Supposons que votre DataFrame soit chargé dans une variable appelée df\n",
    "# df = pd.read_csv('votre_fichier.csv')\n",
    "\n",
    "# 1. Vérifier les valeurs manquantes\n",
    "print(\"Valeurs manquantes avant nettoyage :\")\n",
    "print(train_merge.isnull().sum())\n",
    "\n",
    "# 2. Supprimer les lignes avec des valeurs manquantes (si nécessaire)\n",
    "train_merge = train_merge.dropna()\n",
    "\n",
    "# 3. Supprimer les doublons\n",
    "train_merge = train_merge.drop_duplicates()\n",
    "\n",
    "# 4. Normaliser les données (par exemple, convertir toutes les chaînes en minuscules)\n",
    "train_merge['merged'] = train_merge['merged'].str.lower()\n",
    "\n",
    "# 5. Vérifier les types de données\n",
    "print(\"Types de données après nettoyage :\")\n",
    "print(train_merge.dtypes)\n",
    "\n",
    "# Afficher les premières lignes du DataFrame nettoyé\n",
    "print(\"DataFrame nettoyé :\")\n",
    "print(train_merge.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valeurs uniques dans la colonne 'merged' :\n",
      "['olivia: personalisiertes notizbuch / 150 seiten / punktraster / ca din a5 / rosen-design'\n",
      " \"journal des arts (le) ndeg 133 du 28/09/2001 - l'art et son marche salon d'art asiatique a paris - jacques barrere - francois perrier - la reforme des ventes aux encheres publiques - le sna fete ses cent ans.\"\n",
      " 'grand stylet ergonomique bleu gamepad nintendo wii u - speedlink pilot style pilot style touch pen de marque speedlink est 1 stylet ergonomique pour gamepad nintendo wii u.<br> pour un confort optimal et une precision maximale sur le gamepad de la wii u: ce grand stylet hautement ergonomique est non seulement parfaitement adapte a votre main mais aussi tres elegant.<br> il est livre avec un support qui se fixe sans adhesif a l\\'arriere du gamepad<br> <br> caracteristiques:<br> modele: speedlink pilot style touch pen<br> couleur: bleu<br> ref. fabricant: sl-3468-be<br> compatibilite: gamepad nintendo wii u<br> forme particulierement ergonomique excellente tenue en main<br> pointe a revetement longue duree concue pour ne pas abimer l\\'ecran tactile<br> en bonus : support inclu pour gamepad<br> <span class=\"vga_style2\"><b></b><br>'\n",
      " 'peluche donald - europe - disneyland 2000 (marionnette a doigt)'\n",
      " \"la guerre des tuques luc a des id&eacute;es de grandeur. il veut organiser un jeu de guerre de boules de neige et s'arranger pour en &ecirc;tre le vainqueur incontest&eacute;. mais sophie s'en m&ecirc;le et chambarde tous ses plans...\"\n",
      " 'afrique contemporaine ndeg 212 hiver 2004 - dossier japon / afrique'\n",
      " 'christof e: bildungsprozessen auf der spur'\n",
      " 'conquerant sept cahier couverture polypro 240 x 320 mm 96 pages 90g seyes incolore conquerant classique cahier 240 x 320 mm seyes incolorecouverture en polypro 96 pages agrafe papier de 90 g/m2(400006764)'\n",
      " 'puzzle scooby-doo avec poster 2x35 pieces'\n",
      " 'tente pliante v3s5-pro pvc blanc - 3 x 4m50 - longueur : 4m50 largeur : 3 m blanc h tente pliante v3s5 pro pvc 500 gr/m2 - 3 x 4m50.que vous soyez un particulier pour votre jardin ou un professionnel pour stand commercial ou pour vos receptions le barnum v3s5 pro de 135 m2 sera vous combler.imaginez un <strong>stand</strong> robuste leger adaptable a chacun pliable et peu encombrant... le deploiement ultra-rapide et le reglage de la hauteur se font maintenant via des poignees d&#39;indexage. nous avons egalement entierement repense les pieces de jonction et les coulissants : plus rigides et legeres elles sont aussi maintenant 30% plus resistantes. la <strong>tente pliante</strong> v3 pro de <strong>qualite professionnelle </strong>et de<strong> fabrication francaise </strong>est completement adaptable et deviendra l&#39;outil indispensable a votre activite. toujours en vue d&#39;ameliorer votre quotidien cette version du v3 se veut encore plus resistante au temps.un traitement <strong>ignifuge </strong>repond aux exigences de securite en vigueur (certifie m2) et sa facilite d&#39;entretien en fait un allie pour toutes les occasions.le produit de base est compose d&#39;une structure d&#39;un toit en bache pvc 500 gr/m2 et d&#39;une housse. apres a vous de configurer vos <strong>facades</strong> comme vous le souhaitez.avantages<ul><li>facile a monter</li><li>traitement anti feu</li><li>facades aux choix</li><li><strong>caracteristiques</strong></li><li>coloris blanc</li><li>pvc blanc 500 gr/m2 ignifuge m2</li><li>indexation via poignees : blocage du stand sans effort.</li><li>3 hauteurs reglables via indexeurs.</li><li>croisillons : 1 renfort interne et 2 renforts externes inox.</li><li>embases : fonte d&#39;aluminium (10 mm).</li><li>anneaux d&#39;haubanage.</li><li>structure 100 % aluminium / visserie en inox.</li><li>pieces de jonctions renforcees (polypropylene &#43; 30% fibre de verre) </li><li>fils haute tenacite hydrofuges</li><li>pied coulissant et systeme de guidage integre</li><li>pieds hexagonaux en aluminium (epaisseur 2 mm) </li><li>renforts de toit pvc</li><li>finition du toit integrant un biais serge </li><li>auto agrippant 50 mm </li><li>maintien du toit par auto agrippants</li><li>encombrement referme inferieur a 1m2</li><li>dimensions</li><li>3 x 4m50</li><li>2 mats</li><li>hauteur du faitage 3m10 a 3m26</li><li>hauteur sous bandeau 1m95 a 2m11</li><li>dimensions repliees 035 x 050 x 158m</li></ul>']\n",
      "DataFrame nettoyé après normalisation :\n",
      "    productid     imageid                                             merged\n",
      "0  3804725264  1263597046  olivia personalisiertes notizbuch  150 seiten ...\n",
      "1   436067568  1008141237  journal des arts le ndeg 133 du 28092001  lart...\n",
      "2   201115110   938777978  grand stylet ergonomique bleu gamepad nintendo...\n",
      "3    50418756   457047496  peluche donald  europe  disneyland 2000 marion...\n",
      "4   278535884  1077757786  la guerre des tuques luc a des idées de grande...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import html\n",
    "\n",
    "unique_values = train_merge['merged'].unique()\n",
    "print(\"Valeurs uniques dans la colonne 'merged' :\")\n",
    "print(unique_values[:10])  # Afficher les 10 premières valeurs uniques\n",
    "\n",
    "# 2. Nettoyer les caractères spéciaux et les entités HTML\n",
    "train_merge['merged'] = train_merge['merged'].apply(lambda x: html.unescape(x))\n",
    "train_merge['merged'] = train_merge['merged'].str.replace(r'[^\\w\\s]', '', regex=True)\n",
    "\n",
    "# 3. Vérifier les doublons après normalisation\n",
    "train_merge = train_merge.drop_duplicates()\n",
    "\n",
    "# Afficher les premières lignes du DataFrame nettoyé\n",
    "print(\"DataFrame nettoyé après normalisation :\")\n",
    "print(train_merge.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame nettoyé après normalisation :\n",
      "     productid     imageid                                             merged\n",
      "0   3804725264  1263597046  olivia personalisiertes notizbuch 150 seiten p...\n",
      "1    436067568  1008141237  journal des arts le ndeg 133 du 28092001 lart ...\n",
      "2    201115110   938777978  grand stylet ergonomique bleu gamepad nintendo...\n",
      "3     50418756   457047496  peluche donald europe disneyland 2000 marionne...\n",
      "4    278535884  1077757786  la guerre des tuques luc a des idées de grande...\n",
      "5      5862738   393356830  afrique contemporaine ndeg 212 hiver 2004 doss...\n",
      "6     91920807   907794536          christof e bildungsprozessen auf der spur\n",
      "7    344240059   999581347  conquerant sept cahier couverture polypro 240 ...\n",
      "8   4239126071  1325918866           puzzle scoobydoo avec poster 2x35 pieces\n",
      "9   3793572222  1245644185  tente pliante v3s5pro pvc blanc 3 x 4m50 longu...\n",
      "10  1915836983  1111840281  eames inspired sxw chair pink black the timele...\n",
      "11  4127967621  1295816984  fauteuil chesterfield brenton 100 cuir de buff...\n",
      "12  3287127001  1204199842  peaceable kingdom wheres bear the hide and fin...\n",
      "13  1882164320  1109088140  paire de voilages imprimes fantaisie paire de ...\n",
      "14  4108914287  1292441752  matelas memoire de forme 180x200 x 20 cm tres ...\n",
      "15  3718150116  1237257586  zenith pince agrafeuse 591 ndeg10 coloris noir...\n",
      "16  3735707499  1239242410  walter scott oeuvres completes tomes 3456 10 e...\n",
      "17  2666371748  1156191369                mod podge dishwasher safe gloss 8oz\n",
      "18    91015572   857195931  power rangers rouge force mystic figurine tran...\n",
      "19   570628142  1027257229  monde illustre le ndeg 3083 du 20011917 lempru...\n",
      "20  3936362802  1268740880    kit de desinfection pour piscines enfants 20990\n",
      "21  3228900895  1199384348  glitter beach barbie by barbie original barbie...\n",
      "22  1893048509  1110089245  le seigneur des anneaux figurine en plomb a pe...\n",
      "23   279822475   978593209  vehicule star wars aast5 vehicule vintage de l...\n",
      "24  3748203527  1240721678  mini wifi 720p camera drone rc quadcopter 24 g...\n",
      "25   211334790   948608572                       dsi chargeur sacoche 12 jeux\n",
      "26  4137059841  1297749086  modele de voiture 4pcs alliage metallique 19in...\n",
      "27  2536863974  1148154575  fabercastell lot de 3 crayons de couleur polyc...\n",
      "28   570663184  1027317460  univers l ndeg 249 du 12091854 france paris 11...\n",
      "29  3226779852  1202890774  dragon ball super bt3070 c13 les premisses de ...\n",
      "30  4198487181  1313675704  lampe de lecture rechargeable led lampe de bea...\n",
      "31    49132716   874730792                                   xmen 3 the movie\n",
      "32  3079667218  1195260111  2 cagettes de rangement happy life 40 x 30 cm ...\n",
      "33  3817904723  1248853903  lindner 23652115ce coin case nera xl with 3 tr...\n",
      "34  4237073471  1324384878                              the lord or the rings\n",
      "35  4211197055  1317753478  decoration de noel christmas snowman kitchen t...\n",
      "36  3847254406  1264434293  30 spots encastrable orientable blanc avec gu1...\n",
      "37  4007155304  1275613423  nouveau 01h20 echelle alloy mini pull back voi...\n",
      "38  4012748163  1276344493  4pcs decor coussin independance style jeter co...\n",
      "39  3147314797  1225887302  bouee gonflable river tube oogarden bouee gonf...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import html\n",
    "import re\n",
    "\n",
    "\n",
    "# Fonction pour nettoyer les descriptions\n",
    "def clean_description(text):\n",
    "    # Supprimer les balises HTML\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    # Convertir les entités HTML en caractères normaux\n",
    "    text = html.unescape(text)\n",
    "    # Supprimer les caractères spéciaux\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    # Normaliser les espaces\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "# Appliquer la fonction de nettoyage à la colonne 'merged'\n",
    "train_merge['merged'] = train_merge['merged'].apply(clean_description)\n",
    "\n",
    "# Vérifier les doublons après normalisation\n",
    "train_merge = train_merge.drop_duplicates()\n",
    "\n",
    "# Afficher les premières lignes du DataFrame nettoyé\n",
    "print(\"DataFrame nettoyé après normalisation :\")\n",
    "print(train_merge.head(40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Types de données après nettoyage :\n",
      "productid     int64\n",
      "imageid       int64\n",
      "merged       object\n",
      "dtype: object\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valeurs uniques dans la colonne 'merged' après nettoyage :\n",
      "['olivia personalisiertes notizbuch 150 seiten punktraster ca din a5 rosendesign'\n",
      " 'journal des arts le ndeg 133 du 28092001 lart et son marche salon dart asiatique a paris jacques barrere francois perrier la reforme des ventes aux encheres publiques le sna fete ses cent ans'\n",
      " 'grand stylet ergonomique bleu gamepad nintendo wii u speedlink pilot style pilot style touch pen de marque speedlink est 1 stylet ergonomique pour gamepad nintendo wii ubr pour un confort optimal et une precision maximale sur le gamepad de la wii u ce grand stylet hautement ergonomique est non seulement parfaitement adapte a votre main mais aussi tres elegantbr il est livre avec un support qui se fixe sans adhesif a larriere du gamepadbr br caracteristiquesbr modele speedlink pilot style touch penbr couleur bleubr ref fabricant sl3468bebr compatibilite gamepad nintendo wii ubr forme particulierement ergonomique excellente tenue en mainbr pointe a revetement longue duree concue pour ne pas abimer lecran tactilebr en bonus support inclu pour gamepadbr span classvga_style2bbbr'\n",
      " 'peluche donald europe disneyland 2000 marionnette a doigt'\n",
      " 'la guerre des tuques luc a des idées de grandeur il veut organiser un jeu de guerre de boules de neige et sarranger pour en être le vainqueur incontesté mais sophie sen mêle et chambarde tous ses plans'\n",
      " 'afrique contemporaine ndeg 212 hiver 2004 dossier japon afrique'\n",
      " 'christof e bildungsprozessen auf der spur'\n",
      " 'conquerant sept cahier couverture polypro 240 x 320 mm 96 pages 90g seyes incolore conquerant classique cahier 240 x 320 mm seyes incolorecouverture en polypro 96 pages agrafe papier de 90 gm2400006764'\n",
      " 'puzzle scoobydoo avec poster 2x35 pieces'\n",
      " 'tente pliante v3s5pro pvc blanc 3 x 4m50 longueur 4m50 largeur 3 m blanc h tente pliante v3s5 pro pvc 500 grm2 3 x 4m50que vous soyez un particulier pour votre jardin ou un professionnel pour stand commercial ou pour vos receptions le barnum v3s5 pro de 135 m2 sera vous comblerimaginez un strongstandstrong robuste leger adaptable a chacun pliable et peu encombrant le deploiement ultrarapide et le reglage de la hauteur se font maintenant via des poignees dindexage nous avons egalement entierement repense les pieces de jonction et les coulissants plus rigides et legeres elles sont aussi maintenant 30 plus resistantes la strongtente pliantestrong v3 pro de strongqualite professionnelle stronget destrong fabrication francaise strongest completement adaptable et deviendra loutil indispensable a votre activite toujours en vue dameliorer votre quotidien cette version du v3 se veut encore plus resistante au tempsun traitement strongignifuge strongrepond aux exigences de securite en vigueur certifie m2 et sa facilite dentretien en fait un allie pour toutes les occasionsle produit de base est compose dune structure dun toit en bache pvc 500 grm2 et dune housse apres a vous de configurer vos strongfacadesstrong comme vous le souhaitezavantagesullifacile a monterlilitraitement anti feulilifacades aux choixlilistrongcaracteristiquesstronglilicoloris blanclilipvc blanc 500 grm2 ignifuge m2liliindexation via poignees blocage du stand sans effortlili3 hauteurs reglables via indexeurslilicroisillons 1 renfort interne et 2 renforts externes inoxliliembases fonte daluminium 10 mmlilianneaux dhaubanagelilistructure 100 aluminium visserie en inoxlilipieces de jonctions renforcees polypropylene 30 fibre de verre lilifils haute tenacite hydrofugeslilipied coulissant et systeme de guidage integrelilipieds hexagonaux en aluminium epaisseur 2 mm lilirenforts de toit pvclilifinition du toit integrant un biais serge liliauto agrippant 50 mm lilimaintien du toit par auto agrippantsliliencombrement referme inferieur a 1m2lilidimensionslili3 x 4m50lili2 matslilihauteur du faitage 3m10 a 3m26lilihauteur sous bandeau 1m95 a 2m11lilidimensions repliees 035 x 050 x 158mliul']\n",
      "DataFrame nettoyé final :\n",
      "    productid     imageid                                             merged\n",
      "0  3804725264  1263597046  olivia personalisiertes notizbuch 150 seiten p...\n",
      "1   436067568  1008141237  journal des arts le ndeg 133 du 28092001 lart ...\n",
      "2   201115110   938777978  grand stylet ergonomique bleu gamepad nintendo...\n",
      "3    50418756   457047496  peluche donald europe disneyland 2000 marionne...\n",
      "4   278535884  1077757786  la guerre des tuques luc a des idées de grande...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Supposons que votre DataFrame soit chargé dans une variable appelée df\n",
    "# df = pd.read_csv('votre_fichier.csv')\n",
    "\n",
    "# 1. Vérifier les types de données\n",
    "print(\"Types de données après nettoyage :\")\n",
    "print(train_merge.dtypes)\n",
    "\n",
    "# 2. Vérifier les valeurs uniques dans la colonne 'merged' après nettoyage\n",
    "unique_values = train_merge['merged'].unique()\n",
    "print(\"Valeurs uniques dans la colonne 'merged' après nettoyage :\")\n",
    "print(unique_values[:10])  # Afficher les 10 premières valeurs uniques\n",
    "\n",
    "# 3. Sauvegarder le DataFrame nettoyé\n",
    "train_merge.to_csv('dataframe_nettoye.csv', index=False)\n",
    "\n",
    "# Afficher les premières lignes du DataFrame nettoyé\n",
    "print(\"DataFrame nettoyé final :\")\n",
    "print(train_merge.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame avec descriptions traduites et corrigées :\n",
      "    productid     imageid                                             merged  \\\n",
      "0  3804725264  1263597046  olivia personalisiertes notizbuch 150 seiten p...   \n",
      "1   436067568  1008141237  journal des arts le ndeg 133 du 28092001 lart ...   \n",
      "2   201115110   938777978  grand stylet ergonomique bleu gamepad nintendo...   \n",
      "3    50418756   457047496  peluche donald europe disneyland 2000 marionne...   \n",
      "4   278535884  1077757786  la guerre des tuques luc a des idées de grande...   \n",
      "\n",
      "                                    merged_segmented  \\\n",
      "0  olivia personalisiertes notizbuch 150 seiten p...   \n",
      "1  journal des arts le ndeg 133 du 28092001 lart ...   \n",
      "2  grand stylet ergonomique bleu gamepad nintendo...   \n",
      "3  peluche donald europe disneyland 2000 marionne...   \n",
      "4  la guerre des tuques luc a des idées de grande...   \n",
      "\n",
      "                                    merged_corrected  \n",
      "0  olivia personalisiertes Notizbuch 150 Seiten P...  \n",
      "1  journal des arts le ndeg 133 du 28092001 lart ...  \n",
      "2  grand stylet ergonomique bleu gamepad nintendo...  \n",
      "3  peluche donald europe disneyland 2000 marionne...  \n",
      "4  la guerre des tuques luc a des idées de grande...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Fonction pour segmenter les mots collés\n",
    "def segment_words(text):\n",
    "    # Ajouter des espaces entre les mots collés\n",
    "    text = re.sub(r'([a-z])([A-Z])', r'\\1 \\2', text)\n",
    "    text = re.sub(r'(\\d)([a-zA-Z])', r'\\1 \\2', text)\n",
    "    text = re.sub(r'([a-zA-Z])(\\d)', r'\\1 \\2', text)\n",
    "    return text\n",
    "\n",
    "# Fonction pour corriger l'orthographe (exemple simple, vous pouvez utiliser une bibliothèque plus avancée)\n",
    "def correct_spelling(text):\n",
    "    # Exemple de correction simple, vous pouvez utiliser une bibliothèque comme pyspellchecker pour plus de précision\n",
    "    corrections = {\n",
    "        'personalisiertes': 'personalisiertes',\n",
    "        'notizbuch': 'Notizbuch',\n",
    "        'seiten': 'Seiten',\n",
    "        'punktraster': 'Punktraster',\n",
    "        'din': 'DIN',\n",
    "        'rosendesign': 'Rosendesign'\n",
    "    }\n",
    "    words = text.split()\n",
    "    corrected_words = [corrections.get(word, word) for word in words]\n",
    "    return ' '.join(corrected_words)\n",
    "\n",
    "\n",
    "# Supposons que votre DataFrame soit chargé dans une variable appelée df\n",
    "# df = pd.read_csv('votre_fichier.csv')\n",
    "\n",
    "# Appliquer les fonctions de segmentation, correction et traduction à la colonne 'merged'\n",
    "train_merge['merged_segmented'] = train_merge['merged'].apply(segment_words)\n",
    "train_merge['merged_corrected'] = train_merge['merged_segmented'].apply(correct_spelling)\n",
    "\n",
    "# Afficher les premières lignes du DataFrame avec les descriptions traduites et corrigées\n",
    "print(\"DataFrame avec descriptions traduites et corrigées :\")\n",
    "print(train_merge.head())\n",
    "\n",
    "# Sauvegarder le DataFrame avec les descriptions traduites et corrigées\n",
    "train_merge.to_csv('dataframe_traduit_et_corrige.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 49\u001b[0m\n\u001b[0;32m     46\u001b[0m batches \u001b[38;5;241m=\u001b[39m [train_merge[i\u001b[38;5;241m*\u001b[39mbatch_size:(i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m*\u001b[39mbatch_size]\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_batches)]\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# Utiliser tqdm pour afficher l'avancement\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m processed_batches \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_batch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mProcessing batches\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_batches\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m# Concaténer les lots traités\u001b[39;00m\n\u001b[0;32m     52\u001b[0m train_merge \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(processed_batches)\n",
      "File \u001b[1;32mc:\\Users\\dunca\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dunca\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dunca\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from spellchecker import SpellChecker\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Initialiser le correcteur orthographique pour le français\n",
    "spell = SpellChecker(language='fr')\n",
    "\n",
    "# Fonction pour segmenter les mots collés\n",
    "def segment_words(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    # Ajouter des espaces entre les mots collés\n",
    "    text = re.sub(r'([a-z])([A-Z])', r'\\1 \\2', text)\n",
    "    text = re.sub(r'(\\d)([a-zA-Z])', r'\\1 \\2', text)\n",
    "    text = re.sub(r'([a-zA-Z])(\\d)', r'\\1 \\2', text)\n",
    "    return text\n",
    "\n",
    "# Fonction pour corriger l'orthographe\n",
    "def correct_spelling(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    words = text.split()\n",
    "    corrected_words = [spell.correction(word) or word for word in words]\n",
    "    return ' '.join(corrected_words)\n",
    "\n",
    "# Fonction pour traiter un lot\n",
    "def process_batch(batch):\n",
    "    try:\n",
    "        batch['merged_segmented'] = batch['merged'].apply(segment_words)\n",
    "        batch['merged_corrected'] = batch['merged_segmented'].apply(correct_spelling)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing batch: {e}\")\n",
    "    return batch\n",
    "\n",
    "# Supposons que votre DataFrame soit chargé dans une variable appelée train_merge\n",
    "# train_merge = pd.read_csv('votre_fichier.csv')\n",
    "\n",
    "# Convertir la colonne 'merged' en chaînes de caractères\n",
    "train_merge['merged'] = train_merge['merged'].astype(str)\n",
    "\n",
    "# Traitement par lots avec parallélisation et affichage de l'avancement\n",
    "batch_size = 500  # Réduire la taille des lots pour éviter les problèmes de mémoire\n",
    "num_batches = len(train_merge) // batch_size + 1\n",
    "batches = [train_merge[i*batch_size:(i+1)*batch_size].copy() for i in range(num_batches)]\n",
    "\n",
    "# Utiliser tqdm pour afficher l'avancement\n",
    "processed_batches = Parallel(n_jobs=-1)(delayed(process_batch)(batch) for batch in tqdm(batches, desc=\"Processing batches\", total=num_batches))\n",
    "\n",
    "# Concaténer les lots traités\n",
    "train_merge = pd.concat(processed_batches)\n",
    "\n",
    "# Afficher les premières lignes du DataFrame avec les descriptions corrigées\n",
    "print(\"DataFrame avec descriptions corrigées :\")\n",
    "print(train_merge.head())\n",
    "\n",
    "# Sauvegarder le DataFrame avec les descriptions corrigées\n",
    "train_merge.to_csv('dataframe_corrige.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "detecter la langue,\n",
    "Traduire,\n",
    "Faire le nettoyage des lignes qui ont enormement de caractere (majorité - 4000 certaines a 12000. Faire la moyenne et couper la ligne (tronquer))\n",
    "Equilibre de classes (a voir avec le mentor)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
